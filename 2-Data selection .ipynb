{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babc7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba \n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3f7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data selection\n",
    "df_final_balanced_all= pd.read_csv('df_merged_balanced_all_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01e08da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>nickname</th>\n",
       "      <th>gender</th>\n",
       "      <th>profile</th>\n",
       "      <th>birthday</th>\n",
       "      <th>num_of_follower</th>\n",
       "      <th>num_of_following</th>\n",
       "      <th>all_tweet_count</th>\n",
       "      <th>original_tweet_count</th>\n",
       "      <th>repost_tweet_count</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>南琅子柒</td>\n",
       "      <td>女</td>\n",
       "      <td>很会害羞</td>\n",
       "      <td>水瓶座</td>\n",
       "      <td>413</td>\n",
       "      <td>1672</td>\n",
       "      <td>3634</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>[{'tweet_content': '冲', 'posting_time': '2020-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>en嗯en_怪好</td>\n",
       "      <td>女</td>\n",
       "      <td>我想去一个地方、和你或者是自己看风吹麦浪</td>\n",
       "      <td>无</td>\n",
       "      <td>488</td>\n",
       "      <td>145</td>\n",
       "      <td>1969</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>[{'tweet_content': '拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label  nickname gender               profile birthday  \\\n",
       "0  15315      0      南琅子柒      女                  很会害羞      水瓶座   \n",
       "1  17978      0  en嗯en_怪好      女  我想去一个地方、和你或者是自己看风吹麦浪        无   \n",
       "\n",
       "   num_of_follower  num_of_following  all_tweet_count  original_tweet_count  \\\n",
       "0              413              1672             3634                    50   \n",
       "1              488               145             1969                    41   \n",
       "\n",
       "   repost_tweet_count                                             tweets  \n",
       "0                  32  [{'tweet_content': '冲', 'posting_time': '2020-...  \n",
       "1                  57  [{'tweet_content': '拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_balanced_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b9d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_balanced_all2=df_final_balanced_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb41d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>nickname</th>\n",
       "      <th>gender</th>\n",
       "      <th>profile</th>\n",
       "      <th>birthday</th>\n",
       "      <th>num_of_follower</th>\n",
       "      <th>num_of_following</th>\n",
       "      <th>all_tweet_count</th>\n",
       "      <th>original_tweet_count</th>\n",
       "      <th>repost_tweet_count</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>南琅子柒</td>\n",
       "      <td>女</td>\n",
       "      <td>很会害羞</td>\n",
       "      <td>水瓶座</td>\n",
       "      <td>413</td>\n",
       "      <td>1672</td>\n",
       "      <td>3634</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>[{'tweet_content': '冲', 'posting_time': '2020-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>en嗯en_怪好</td>\n",
       "      <td>女</td>\n",
       "      <td>我想去一个地方、和你或者是自己看风吹麦浪</td>\n",
       "      <td>无</td>\n",
       "      <td>488</td>\n",
       "      <td>145</td>\n",
       "      <td>1969</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>[{'tweet_content': '拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label  nickname gender               profile birthday  \\\n",
       "0  15315      0      南琅子柒      女                  很会害羞      水瓶座   \n",
       "1  17978      0  en嗯en_怪好      女  我想去一个地方、和你或者是自己看风吹麦浪        无   \n",
       "\n",
       "   num_of_follower  num_of_following  all_tweet_count  original_tweet_count  \\\n",
       "0              413              1672             3634                    50   \n",
       "1              488               145             1969                    41   \n",
       "\n",
       "   repost_tweet_count                                             tweets  \n",
       "0                  32  [{'tweet_content': '冲', 'posting_time': '2020-...  \n",
       "1                  57  [{'tweet_content': '拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_balanced_all2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbe8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_balanced_all_tweets = df_final_balanced_all2[['ID', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7071f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import ast\n",
    "\n",
    "# Assuming 'tweets' column contains string representations of lists\n",
    "df_final_balanced_all2['tweets'] = df_final_balanced_all2['tweets'].apply(ast.literal_eval)\n",
    "\n",
    "# Now apply your lambda function\n",
    "df_final_balanced_all_tweets['tweet_content'] = df_final_balanced_all2['tweets'].apply(lambda x: [d['tweet_content'] for d in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35dbe665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>[冲, 害 我真的挺吃lyw的颜 但一想到他只有14岁我就, 足以表达我减肥的决心了, 无,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>[拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 坎坷 不安 在一个人慌乱的时候 也许有...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>[下雨天别穿max97 会滑倒 坐水里 亲测, 我艾特曾子赟相信大家都不会有意见的对吧, 麻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>[有一种幸福～叫做一桌菜然后看着家人朋友满足的吃完 就是没人帮忙刷碗, 老规矩, 昨晚本想做...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>[无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label                                      tweet_content\n",
       "0  15315      0  [冲, 害 我真的挺吃lyw的颜 但一想到他只有14岁我就, 足以表达我减肥的决心了, 无,...\n",
       "1  17978      0  [拥抱是这个世界上最暖心的动作吧 生活中难免遇到挫折 坎坷 不安 在一个人慌乱的时候 也许有...\n",
       "2    221      0  [下雨天别穿max97 会滑倒 坐水里 亲测, 我艾特曾子赟相信大家都不会有意见的对吧, 麻...\n",
       "3  16604      0  [有一种幸福～叫做一桌菜然后看着家人朋友满足的吃完 就是没人帮忙刷碗, 老规矩, 昨晚本想做...\n",
       "4  20755      0  [无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, 无, ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_balanced_all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58eff8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after data balance1\n",
    "grouped_label = df_final_balanced_all_tweets.groupby(['label', ]).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abec86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      0  10325\n",
       "1      1  10325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "287452d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final data to CSV file\n",
    "df_final_balanced_all_tweets.to_csv('df_final_balanced_ID_label_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9dbeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean\n",
    "balanced_df_all = pd.read_csv('df_final_balanced_ID_label_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cdc5111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>['冲', '害 我真的挺吃lyw的颜 但一想到他只有14岁我就', '足以表达我减肥的决心...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label                                      tweet_content\n",
       "0  15315      0  ['冲', '害 我真的挺吃lyw的颜 但一想到他只有14岁我就', '足以表达我减肥的决心..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all.loc[balanced_df_all['ID'] == 15315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3128316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>['下雨天别穿max97 会滑倒 坐水里 亲测', '我艾特曾子赟相信大家都不会有意见的对吧...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>['您居然向我这样的反英灵施于如此恩情如梦般喜悦如朝露般缥缈―――因为这样一来分别时会很痛苦...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  label                                      tweet_content\n",
       "2      221      0  ['下雨天别穿max97 会滑倒 坐水里 亲测', '我艾特曾子赟相信大家都不会有意见的对吧...\n",
       "10545  221      1  ['您居然向我这样的反英灵施于如此恩情如梦般喜悦如朝露般缥缈―――因为这样一来分别时会很痛苦..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all.loc[balanced_df_all['ID'] == 221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a498432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "with open('cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4187f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "   \n",
    "    # Remove numbers, emojis, punctuations,special charts,shared posts, hashtags\n",
    "    # Only Chinese characters are reserved.\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fff]+', '', text)\n",
    "    \n",
    "    # Remove weibo stop words\n",
    "    for word in stopwords:\n",
    "        if word in text:\n",
    "            text = re.sub(word, '', text)   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f2c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned = balanced_df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1c10395",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned.loc[:, 'tweet_content'] = balanced_df_all_cleaned['tweet_content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f061ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>10322</td>\n",
       "      <td>1</td>\n",
       "      <td>太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20647</th>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>10324</td>\n",
       "      <td>1</td>\n",
       "      <td>果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20649</th>\n",
       "      <td>10325</td>\n",
       "      <td>1</td>\n",
       "      <td>面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "0      15315      0  害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...\n",
       "1      17978      0  拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...\n",
       "2        221      0  雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...\n",
       "3      16604      0  种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...\n",
       "4      20755      0  日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...\n",
       "...      ...    ...                                                ...\n",
       "20645  10321      1  意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...\n",
       "20646  10322      1  太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...\n",
       "20647  10323      1  种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...\n",
       "20648  10324      1  果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...\n",
       "20649  10325      1  面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...\n",
       "\n",
       "[20650 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d958fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "balanced_df_all_cleaned.to_csv('balanced_df_all_cleaned.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b6d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenication\n",
    "balanced_df_all_cleaned = pd.read_csv('balanced_df_all_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d58e1e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "20645  10321      1  意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned.loc[balanced_df_all_cleaned['ID'] == 10321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a663762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>10322</td>\n",
       "      <td>1</td>\n",
       "      <td>太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20647</th>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>10324</td>\n",
       "      <td>1</td>\n",
       "      <td>果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20649</th>\n",
       "      <td>10325</td>\n",
       "      <td>1</td>\n",
       "      <td>面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "0      15315      0  害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...\n",
       "1      17978      0  拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...\n",
       "2        221      0  雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...\n",
       "3      16604      0  种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...\n",
       "4      20755      0  日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...\n",
       "...      ...    ...                                                ...\n",
       "20645  10321      1  意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...\n",
       "20646  10322      1  太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...\n",
       "20647  10323      1  种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...\n",
       "20648  10324      1  果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...\n",
       "20649  10325      1  面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...\n",
       "\n",
       "[20650 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60c8fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned2 = balanced_df_all_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f01a408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>10322</td>\n",
       "      <td>1</td>\n",
       "      <td>太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20647</th>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>10324</td>\n",
       "      <td>1</td>\n",
       "      <td>果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20649</th>\n",
       "      <td>10325</td>\n",
       "      <td>1</td>\n",
       "      <td>面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "0      15315      0  害真挺吃颜想岁足表达减肥决心姐妹谈恋爱什感觉全世界闺蜜介绍成功行淦近什新情侣装评手评寻思俩关...\n",
       "1      17978      0  拥抱世界暖心动作生活中难免遇挫折坎坷安慌乱许时拥抱会充满量继续世界抗衡愿生山树栖心爱春赏花夏...\n",
       "2        221      0  雨天穿会滑倒坐水里亲测艾特子赟相信家会意见麻雀妈妈问麻雀天扎什头发麻雀说啾啾晚子赟帮辫头发突...\n",
       "3      16604      0  种幸福做桌菜然家朋友满足吃完没帮忙刷碗老规矩昨晚想做早餐奶包发酵忘遛弯回变成馒头样子朋友吃午...\n",
       "4      20755      0  日清明青草疫情中牺牲医护员公安干警基层干部线工作逝世胞表示沉痛悼念情病毒面前选择逆行选择死生...\n",
       "...      ...    ...                                                ...\n",
       "20645  10321      1  意做件错事真久久原谅近发生事情绪波动房间突然爆哭然雨天跑出外面冻两时爸妈姨表哥电话接妈妈外面...\n",
       "20646  10322      1  太喜欢张教授说话特实危言耸听然整体说认识医生亲戚朋友医生医生子女微博关注医生部分说话客观尤专...\n",
       "20647  10323      1  种毒药断送爱常常听说爱情蜜糖深陷中会沉醉岂知份爱情美会意想原理结束常常意想称爱情毒药爱情会什...\n",
       "20648  10324      1  果原谅痛苦值降低现贼悔吃麻辣串洗完澡新换衣服全味难受天新闻男熬夜猝死死女抑郁症确诊天昨天加药...\n",
       "20649  10325      1  面兽心衣冠禽兽说种求助警方包庇社会真药救希正义早日坏绳法回分装爱朵手抖漏时间觉浓行跑出房间五...\n",
       "\n",
       "[20650 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "959a304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned2['tweet_content'] = balanced_df_all_cleaned2['tweet_content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bcecdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.900 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "balanced_df_all_cleaned2['tweet_content'] = balanced_df_all_cleaned2['tweet_content'].apply(lambda x: ' '.join(jieba.cut(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57216c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件 错事 真 久久 原谅 近 发生 事 情绪 波动 房间 突然 爆哭然 雨天 跑 出 外...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>10322</td>\n",
       "      <td>1</td>\n",
       "      <td>太 喜欢 张 教授 说话 特实 危言耸听 然 整体 说 认识 医生 亲戚朋友 医生 医生 子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20647</th>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>种 毒药 断送 爱 常常 听说 爱情 蜜糖 深陷 中 会 沉醉 岂知 份 爱情 美 会意 想...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>10324</td>\n",
       "      <td>1</td>\n",
       "      <td>果 原谅 痛苦 值 降低 现贼 悔 吃 麻辣 串 洗完 澡 新 换衣服 全味 难受 天 新闻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20649</th>\n",
       "      <td>10325</td>\n",
       "      <td>1</td>\n",
       "      <td>面 兽心 衣冠禽兽 说种 求助 警方 包庇 社会 真药 救希 正义 早日 坏 绳法 回 分装...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "0      15315      0  害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...\n",
       "1      17978      0  拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...\n",
       "2        221      0  雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...\n",
       "3      16604      0  种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...\n",
       "4      20755      0  日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛...\n",
       "...      ...    ...                                                ...\n",
       "20645  10321      1  意做件 错事 真 久久 原谅 近 发生 事 情绪 波动 房间 突然 爆哭然 雨天 跑 出 外...\n",
       "20646  10322      1  太 喜欢 张 教授 说话 特实 危言耸听 然 整体 说 认识 医生 亲戚朋友 医生 医生 子...\n",
       "20647  10323      1  种 毒药 断送 爱 常常 听说 爱情 蜜糖 深陷 中 会 沉醉 岂知 份 爱情 美 会意 想...\n",
       "20648  10324      1  果 原谅 痛苦 值 降低 现贼 悔 吃 麻辣 串 洗完 澡 新 换衣服 全味 难受 天 新闻...\n",
       "20649  10325      1  面 兽心 衣冠禽兽 说种 求助 警方 包庇 社会 真药 救希 正义 早日 坏 绳法 回 分装...\n",
       "\n",
       "[20650 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dde59704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "balanced_df_all_cleaned2.to_csv('balanced_df_all_cleaned_tokenization.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "770bf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "balanced_df_all_cleaned_tokenization = pd.read_csv('balanced_df_all_cleaned_tokenization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd369ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>10321</td>\n",
       "      <td>1</td>\n",
       "      <td>意做件 错事 真 久久 原谅 近 发生 事 情绪 波动 房间 突然 爆哭然 雨天 跑 出 外...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646</th>\n",
       "      <td>10322</td>\n",
       "      <td>1</td>\n",
       "      <td>太 喜欢 张 教授 说话 特实 危言耸听 然 整体 说 认识 医生 亲戚朋友 医生 医生 子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20647</th>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>种 毒药 断送 爱 常常 听说 爱情 蜜糖 深陷 中 会 沉醉 岂知 份 爱情 美 会意 想...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>10324</td>\n",
       "      <td>1</td>\n",
       "      <td>果 原谅 痛苦 值 降低 现贼 悔 吃 麻辣 串 洗完 澡 新 换衣服 全味 难受 天 新闻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20649</th>\n",
       "      <td>10325</td>\n",
       "      <td>1</td>\n",
       "      <td>面 兽心 衣冠禽兽 说种 求助 警方 包庇 社会 真药 救希 正义 早日 坏 绳法 回 分装...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                                      tweet_content\n",
       "0      15315      0  害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...\n",
       "1      17978      0  拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...\n",
       "2        221      0  雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...\n",
       "3      16604      0  种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...\n",
       "4      20755      0  日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛...\n",
       "...      ...    ...                                                ...\n",
       "20645  10321      1  意做件 错事 真 久久 原谅 近 发生 事 情绪 波动 房间 突然 爆哭然 雨天 跑 出 外...\n",
       "20646  10322      1  太 喜欢 张 教授 说话 特实 危言耸听 然 整体 说 认识 医生 亲戚朋友 医生 医生 子...\n",
       "20647  10323      1  种 毒药 断送 爱 常常 听说 爱情 蜜糖 深陷 中 会 沉醉 岂知 份 爱情 美 会意 想...\n",
       "20648  10324      1  果 原谅 痛苦 值 降低 现贼 悔 吃 麻辣 串 洗完 澡 新 换衣服 全味 难受 天 新闻...\n",
       "20649  10325      1  面 兽心 衣冠禽兽 说种 求助 警方 包庇 社会 真药 救希 正义 早日 坏 绳法 回 分装...\n",
       "\n",
       "[20650 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all_cleaned_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d540eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned_tokenization2 = balanced_df_all_cleaned_tokenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e67d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values with an empty string\n",
    "balanced_df_all_cleaned_tokenization2['tweet_content'] = balanced_df_all_cleaned_tokenization2['tweet_content'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71423eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TfidfVectorizer object 将tweet_content列作为特征向量化\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8823c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29c837f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the data\n",
    "X = vectorizer.fit_transform(balanced_df_all_cleaned_tokenization2['tweet_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89716e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20650x983994 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11403990 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17636ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = balanced_df_all_cleaned_tokenization2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ccc553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20650, 983994), (20650,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "144c9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model RF\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99372b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b702e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82314c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to identify 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da8004eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=13)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=13) # 修改树的棵树， 使用10折交叉验证来确定n_estimators的最佳值为13\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fed1ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=13)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=13) # 修改树的棵树， 使用10折交叉验证来确定n_estimators的最佳值为13\n",
    "rfc.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9201ec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=13)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=13) # 修改树的棵树， 使用10折交叉验证来确定n_estimators的最佳值为13\n",
    "rfc.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd61b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a911251",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc2 = rfc.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fef7b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc3 = rfc.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9dcbca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9601291364003228\n",
      "Precision: 0.9652986319652986\n",
      "Recall: 0.9528985507246377\n",
      "F1 Score: 0.9590585115199736\n"
     ]
    }
   ],
   "source": [
    "# 计算模型评估指标\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rfc)\n",
    "precision_rf = precision_score(y_test, y_pred_rfc)\n",
    "recall_rf = recall_score(y_test, y_pred_rfc)\n",
    "f1_rf = f1_score(y_test, y_pred_rfc)\n",
    "\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Precision:', precision_rf)\n",
    "print('Recall:', recall_rf)\n",
    "print('F1 Score:', f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c57982d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9026634382566586\n",
      "Precision: 0.9139758442198669\n",
      "Recall: 0.8907038193610377\n",
      "F1 Score: 0.9021897810218978\n"
     ]
    }
   ],
   "source": [
    "# 计算模型评估指标 2\n",
    "accuracy_rf = accuracy_score(y_test2, y_pred_rfc2)\n",
    "precision_rf = precision_score(y_test2, y_pred_rfc2)\n",
    "recall_rf = recall_score(y_test2, y_pred_rfc2)\n",
    "f1_rf = f1_score(y_test2, y_pred_rfc2)\n",
    "\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Precision:', precision_rf)\n",
    "print('Recall:', recall_rf)\n",
    "print('F1 Score:', f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4c3a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9096852300242131\n",
      "Precision: 0.9207873259721555\n",
      "Recall: 0.9021636876763875\n",
      "F1 Score: 0.9113803753860775\n"
     ]
    }
   ],
   "source": [
    "# 计算模型评估指标 2\n",
    "accuracy_rf = accuracy_score(y_test3, y_pred_rfc3)\n",
    "precision_rf = precision_score(y_test3, y_pred_rfc3)\n",
    "recall_rf = recall_score(y_test3, y_pred_rfc3)\n",
    "f1_rf = f1_score(y_test3, y_pred_rfc3)\n",
    "\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Precision:', precision_rf)\n",
    "print('Recall:', recall_rf)\n",
    "print('F1 Score:', f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b24abe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "RF: [0]\n"
     ]
    }
   ],
   "source": [
    "# normal content\n",
    "new_tweet_content = ['这是 一条 新的 正常 推文']\n",
    "\n",
    "# depressed content\n",
    "# new_tweet_content = ['思 诺思 舒乐安定 代开 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# RF\n",
    "new_y_pred_rfc = rfc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('RF:', new_y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5409d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "RF: [1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# depressed content\n",
    "new_tweet_content = ['思 诺思 舒乐安定 代开 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# RF\n",
    "new_y_pred_rfc = rfc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('RF:', new_y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b39a188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed794a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试集的label\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "888db034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine:\n",
      "Accuracy: 0.9465698143664245\n",
      "Precision: 0.982174688057041\n",
      "Recall: 0.9074440052700923\n",
      "F1 Score: 0.9433316212977231\n"
     ]
    }
   ],
   "source": [
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "print('\\nSupport Vector Machine:')\n",
    "print('Accuracy:', accuracy_svc)\n",
    "print('Precision:', precision_svc)\n",
    "print('Recall:', recall_svc)\n",
    "print('F1 Score:', f1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4b150dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "SVM: [1]\n"
     ]
    }
   ],
   "source": [
    "# normal content\n",
    "# new_tweet_content = ['这是 一条 新的 正常 推文']\n",
    "\n",
    "# depressed content\n",
    "new_tweet_content = ['思 诺思 舒乐安定 代开 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# SVM\n",
    "new_y_pred_svc = svc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('SVM:', new_y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11325d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "SVM: [0]\n"
     ]
    }
   ],
   "source": [
    "# normal content\n",
    "new_tweet_content = ['这是 一条 新的 正常 推文']\n",
    "\n",
    "# depressed content\n",
    "# new_tweet_content = ['思 诺思 舒乐安定 代开 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# SVM\n",
    "new_y_pred_svc = svc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('SVM:', new_y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f997052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c041dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "balanced_df_all_cleaned_tokenization = pd.read_csv('balanced_df_all_cleaned_tokenization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8bf98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned_tokenization['tweet_content'] = balanced_df_all_cleaned_tokenization['tweet_content'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec55ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=balanced_df_all_cleaned_tokenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3039ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15315</td>\n",
       "      <td>0</td>\n",
       "      <td>害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17978</td>\n",
       "      <td>0</td>\n",
       "      <td>拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604</td>\n",
       "      <td>0</td>\n",
       "      <td>种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20755</td>\n",
       "      <td>0</td>\n",
       "      <td>日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label                                      tweet_content\n",
       "0  15315      0  害真 挺 吃 颜想 岁 足 表达 减肥 决心 姐妹 谈恋爱 什 感觉 全世界 闺蜜 介绍 成...\n",
       "1  17978      0  拥抱 世界 暖心 动作 生活 中 难免 遇 挫折 坎坷 安 慌乱 许时 拥抱 会 充满 量 ...\n",
       "2    221      0  雨天 穿会 滑倒 坐水里 亲测 艾特子 赟 相信 家会 意见 麻雀 妈妈 问 麻雀 天扎什 ...\n",
       "3  16604      0  种 幸福 做 桌菜 然家 朋友 满足 吃 完 没 帮忙 刷碗 老规矩 昨晚 想 做 早餐 奶...\n",
       "4  20755      0  日 清明 青草 疫情 中 牺牲 医护 员 公安干警 基层干部 线 工作 逝世 胞 表示 沉痛..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4369797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = df3['tweet_content']\n",
    "y = df3['label']\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372d65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.717 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sequences using Jieba tokenizer\n",
    "import jieba \n",
    "import jieba.analyse\n",
    "def tokenize(text):\n",
    "    return list(jieba.cut(text))\n",
    "X_train_sequences = [' '.join(tokenize(x)) for x in X_train]\n",
    "X_test_sequences = [' '.join(tokenize(x)) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "146a0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d097edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to integer sequences\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train_sequences)\n",
    "\n",
    "# Convert tokenized sequences to integer sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train_sequences)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a468b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_length = 7000  # Set the maximum sequence length for padding\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f45991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6195, 7000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d0180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "452/452 [==============================] - 584s 1s/step - loss: 0.2209 - accuracy: 0.9126 - val_loss: 0.0996 - val_accuracy: 0.9656\n",
      "Epoch 2/10\n",
      "452/452 [==============================] - 595s 1s/step - loss: 0.0802 - accuracy: 0.9736 - val_loss: 0.0914 - val_accuracy: 0.9671\n",
      "Epoch 3/10\n",
      "452/452 [==============================] - 603s 1s/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0999 - val_accuracy: 0.9663\n",
      "Epoch 4/10\n",
      "452/452 [==============================] - 595s 1s/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.1095 - val_accuracy: 0.9653\n",
      "Epoch 5/10\n",
      "452/452 [==============================] - 588s 1s/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.1151 - val_accuracy: 0.9664\n",
      "Epoch 6/10\n",
      "452/452 [==============================] - 493s 1s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1261 - val_accuracy: 0.9653\n",
      "Epoch 7/10\n",
      "452/452 [==============================] - 511s 1s/step - loss: 9.3956e-04 - accuracy: 0.9999 - val_loss: 0.1311 - val_accuracy: 0.9659\n",
      "Epoch 8/10\n",
      "452/452 [==============================] - 591s 1s/step - loss: 7.2418e-04 - accuracy: 0.9999 - val_loss: 0.1411 - val_accuracy: 0.9646\n",
      "Epoch 9/10\n",
      "452/452 [==============================] - 610s 1s/step - loss: 6.4881e-04 - accuracy: 0.9999 - val_loss: 0.1453 - val_accuracy: 0.9648\n",
      "Epoch 10/10\n",
      "452/452 [==============================] - 581s 1s/step - loss: 3.2714e-04 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9630\n",
      "194/194 [==============================] - 36s 181ms/step\n",
      "Accuracy: 0.9630347054075867\n",
      "F1 Score: 0.9623293304819872\n",
      "Recall: 0.9509102730819246\n",
      "Precision: 0.974025974025974\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "embedding_dim = 100\n",
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(max_sequence_length,))\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim)(inputs)\n",
    "conv_layers = []\n",
    "for filter_size in filter_sizes:\n",
    "    conv_layer = tf.keras.layers.Conv1D(num_filters, filter_size, activation='relu')(embedding_layer)\n",
    "    pool_layer = tf.keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "    conv_layers.append(pool_layer)\n",
    "concatenated = tf.keras.layers.Concatenate()(conv_layers)\n",
    "dropout = tf.keras.layers.Dropout(0.5)(concatenated)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "history = model.fit(X_train_padded, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test_padded, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518d7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d937e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9744f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d6b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using Jieba (you have already done this)\n",
    "X_train_sequences = [' '.join(tokenize(x)) for x in X_train]\n",
    "X_test_sequences = [' '.join(tokenize(x)) for x in X_test]\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)  # Use a Chinese BERT model\n",
    "\n",
    "# Convert tokenized sequences to integer sequences\n",
    "X_train_sequences = tokenizer(X_train_sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "X_test_sequences = tokenizer(X_test_sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensors = X_train_sequences['input_ids']\n",
    "X_test_tensors = X_test_sequences['input_ids']\n",
    "y_train_tensors = torch.tensor(y_train.values)\n",
    "y_test_tensors = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bef00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create TensorDatasets\n",
    "train_data = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "test_data = TensorDataset(X_test_tensors, y_test_tensors)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd041a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|█▌                                                            | 5/194 [4:46:50<168:07:51, 3202.49s/it]"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "#         input_ids, attention_masks, labels = batch\n",
    "#         outputs = model(input_ids, attention_mask=attention_masks)\n",
    "#         logits = outputs.logits\n",
    "#         predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "#         y_true.extend(labels.cpu().numpy())\n",
    "#         y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, labels = batch  # Remove attention_masks from unpacking\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Your evaluation logic here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dce807",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
